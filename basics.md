**Gen AI**

**Language Models**: Language Models can be used for multiple tasks by learning to Predict next Token/Sentence.

Example - 
  
  **BERT** : Bidirectional Encoder Representations From Transformers, 
  
  **GPT**: Generative Pre-Trained Transformer


Scaling Laws of Neural Language Models: This paper from openai shares insights about how loss factor is linear for Compute, Dataset Size and Model Size



**One hot Encoding**:

**Embeddings**:

**Transformers**: 



