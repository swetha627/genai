It is an art of crafting the instructions to get the most accurate and helpful responses from AI models

1. **Zero-Shot Prompting:**

  LLMs are asked to generate without any prior exmaples/context. It relies entirely on the LLMS genreal understanding of the task


2. **Few-Shot Prompting:**

  You prvoide LLM with few exmaples to guide its response> As a general rule of thumb proovide 3 to 5 relevant examples

3. **Multi-Shot Prompting:**

  It is an extension of Few-Shot prompting, Where you prvoide multiple examples and progressively refine the task

4. **System Prompting:**

  System Prompting sets the context and purpose for the LLM. You can mention system prompt to generate json responses etc.

5. **Role Prompting:**

  It assigns a character/identity for the LLM to adopt you can assign roles like grade school teacher, New york time editor etc.
  Roles add a layer of specificity and personality.

6. **Chain of Thought:**

  It improves the reasoning capabilities of LLMs by genearating intermediate reasoning steps. Add **"Let's think step by step"** to you prompt and you should see the LLM exaplaining each step

7. **Tree of Thought:**

  Allows LLM's to explore multiple reasoning paths. ToT is the generalization of CoT.
  Rather than following a single path as in CoT, ToT follows multiple paths

8. **ReAct Prompting:**
  Reason and Act prompting is a paradigm for enabling LLMs to solve complex tasks using natural language combined with externals tools.
  


  
